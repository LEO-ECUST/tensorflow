{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_DATA\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_DATA\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_DATA\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_DATA\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_DATA',one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter0 Testing Accuracy0.8242\n",
      "Iter1 Testing Accuracy0.8934\n",
      "Iter2 Testing Accuracy0.9014\n",
      "Iter3 Testing Accuracy0.9055\n",
      "Iter4 Testing Accuracy0.9086\n",
      "Iter5 Testing Accuracy0.9103\n",
      "Iter6 Testing Accuracy0.9123\n",
      "Iter7 Testing Accuracy0.9129\n",
      "Iter8 Testing Accuracy0.9153\n",
      "Iter9 Testing Accuracy0.9159\n",
      "Iter10 Testing Accuracy0.9179\n",
      "Iter11 Testing Accuracy0.9192\n",
      "Iter12 Testing Accuracy0.9182\n",
      "Iter13 Testing Accuracy0.9192\n",
      "Iter14 Testing Accuracy0.9194\n",
      "Iter15 Testing Accuracy0.9207\n",
      "Iter16 Testing Accuracy0.9209\n",
      "Iter17 Testing Accuracy0.921\n",
      "Iter18 Testing Accuracy0.921\n",
      "Iter19 Testing Accuracy0.9216\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100   #每个批次大小\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "prediction = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "\n",
    "# loss = tf.reduce_mean(tf.square(y- prediction))\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y,logits = prediction))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "#结果存放于一个布尔列表中\n",
    "corrent_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1)) #argmax()返回一维张量中最大值所在的位置\n",
    "#求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(corrent_prediction,tf.float32)) #cast() 把bool值转化为0,1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(20):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step, feed_dict = {x: batch_xs,y: batch_ys})\n",
    "        acc = sess.run(accuracy,feed_dict = {x:mnist.test.images,y: mnist.test.labels})\n",
    "        print('Iter'+str(epoch)+' Testing Accuracy'+str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 二次代价函数\n",
    "# Iter0 Testing Accuracy0.8302\n",
    "# Iter1 Testing Accuracy0.8699\n",
    "# Iter2 Testing Accuracy0.8809\n",
    "# Iter3 Testing Accuracy0.8878\n",
    "# Iter4 Testing Accuracy0.8942\n",
    "# Iter5 Testing Accuracy0.8969\n",
    "# Iter6 Testing Accuracy0.8999\n",
    "# Iter7 Testing Accuracy0.9025\n",
    "# Iter8 Testing Accuracy0.9029\n",
    "# Iter9 Testing Accuracy0.904\n",
    "# Iter10 Testing Accuracy0.9064\n",
    "# Iter11 Testing Accuracy0.9069\n",
    "# Iter12 Testing Accuracy0.9077\n",
    "# Iter13 Testing Accuracy0.9095\n",
    "# Iter14 Testing Accuracy0.9099\n",
    "# Iter15 Testing Accuracy0.9105\n",
    "# Iter16 Testing Accuracy0.9114\n",
    "# Iter17 Testing Accuracy0.9122\n",
    "# Iter18 Testing Accuracy0.9125\n",
    "# Iter19 Testing Accuracy0.913\n",
    "# # 交叉熵\n",
    "# Iter0 Testing Accuracy0.8242\n",
    "# Iter1 Testing Accuracy0.8934\n",
    "# Iter2 Testing Accuracy0.9014\n",
    "# Iter3 Testing Accuracy0.9055\n",
    "# Iter4 Testing Accuracy0.9086\n",
    "# Iter5 Testing Accuracy0.9103\n",
    "# Iter6 Testing Accuracy0.9123\n",
    "# Iter7 Testing Accuracy0.9129\n",
    "# Iter8 Testing Accuracy0.9153\n",
    "# Iter9 Testing Accuracy0.9159\n",
    "# Iter10 Testing Accuracy0.9179\n",
    "# Iter11 Testing Accuracy0.9192\n",
    "# Iter12 Testing Accuracy0.9182\n",
    "# Iter13 Testing Accuracy0.9192\n",
    "# Iter14 Testing Accuracy0.9194\n",
    "# Iter15 Testing Accuracy0.9207\n",
    "# Iter16 Testing Accuracy0.9209\n",
    "# Iter17 Testing Accuracy0.921\n",
    "# Iter18 Testing Accuracy0.921\n",
    "# Iter19 Testing Accuracy0.9216"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100   #每个批次大小\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "\n",
    "#创建神经网络\n",
    "W1 = tf.Variable(tf.truncated_normal([784,200],stddev = 0.1))\n",
    "b1 = tf.Variable(tf.zeros([200]) +0.1)\n",
    "L1 = tf.nn.tanh(tf.matmul(x,W1) +b1)\n",
    "L1_drop = tf.nn.dropout(L1,keep_prob)\n",
    "\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([200,200],stddev = 0.1))\n",
    "b2 = tf.Variable(tf.zeros([200]) +0.1)\n",
    "L2 = tf.nn.tanh(tf.matmul(L1_drop,W2) +b2)\n",
    "L2_drop = tf.nn.dropout(L2,keep_prob)\n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal([200,100],stddev = 0.1))\n",
    "b3 = tf.Variable(tf.zeros([100]) +0.1)\n",
    "L3 = tf.nn.tanh(tf.matmul(L2_drop,W3) +b3)\n",
    "L3_drop = tf.nn.dropout(L3,keep_prob)\n",
    "\n",
    "\n",
    "W4 = tf.Variable(tf.truncated_normal([100,10],stddev = 0.1))\n",
    "b4 = tf.Variable(tf.zeros([10]) +0.1)\n",
    "prediction = tf.nn.softmax(tf.matmul(L3_drop,W4) + b4)\n",
    "\n",
    "# loss = tf.reduce_mean(tf.square(y- prediction))\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y,logits = prediction))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "#结果存放于一个布尔列表中\n",
    "corrent_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1)) #argmax()返回一维张量中最大值所在的位置\n",
    "#求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(corrent_prediction,tf.float32)) #cast() 把bool值转化为0,1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(20):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step, feed_dict = {x: batch_xs,y: batch_ys,keep_prob:1.0})\n",
    "        train_acc = sess.run(accuracy,feed_dict = {x:mnist.train.images,y: mnist.train.labels,keep_prob : 1.0})\n",
    "        test_acc = sess.run(accuracy,feed_dict = {x:mnist.test.images,y: mnist.test.labels,keep_prob : 1.0})\n",
    "        print('Iter'+str(epoch)+', Training Accuracy:'+str(train_acc)+', Testing Accuracy:'+str(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
